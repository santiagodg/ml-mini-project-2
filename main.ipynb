{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f014b6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Perceptron as sk_Perceptron\n",
    "from sklearn.model_selection import LeaveOneOut as sk_LeaveOneOut\n",
    "from sklearn.model_selection import KFold as sk_KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d22ff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(ABC):\n",
    "    \"\"\"Interface for classifier algorithms.\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit classifier according to X, y.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training vectors, where `n_samples` is the number of samples\n",
    "            and `n_features` is the number of features.\n",
    "        \n",
    "        y : array-like of shape (n_samples,)\n",
    "            Target values.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns the instance itself.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, X):\n",
    "        \"\"\"Perform classification on an array of test vectors X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Input samples.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        C : ndarray of shape (n_samples,)\n",
    "            Predicted target values for X.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "class CrossValidation(ABC):\n",
    "    \"\"\"Interface for cross validation schemes.\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def split(self, X, y=None):\n",
    "        \"\"\"Generate indices to split data into training and test set\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training vectors, where `n_samples` is the number of samples\n",
    "            and `n_features` is the number of features.\n",
    "        \n",
    "        y : array-like of shape (n_samples,)\n",
    "            Target values.\n",
    "        \n",
    "        random_state : int\n",
    "            `random_state` affects the ordering of the indices, which\n",
    "            controls the randomness of each fold.\n",
    "        \n",
    "        Yields\n",
    "        ------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        \n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "class Evaluator(ABC):\n",
    "    \"\"\"Evaluates prediction performance\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def score(self, y_true, y_pred):\n",
    "        \"\"\"Evaluates prediction score.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true : 1d array-like, or label indicator array / sparse matrix\n",
    "            Ground truth (correct) labels.\n",
    "        \n",
    "        y_pred : 1d array-like, or label indicator array / sparse matrix\n",
    "            Predicted labels, as returned by a classifier.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        score : float\n",
    "            Evaluated prediction score.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "class NaiveBayes(Classifier):\n",
    "    \"\"\"Naive Bayes classification algorithm.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.__clf = GaussianNB()\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.__clf.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.__clf.predict(X)\n",
    "\n",
    "class DecisionTrees(Classifier):\n",
    "    \"\"\"Decision tree classifier.\"\"\"\n",
    "    \n",
    "    def __init__(self, random_state: int = None):\n",
    "        self.__clf = DecisionTreeClassifier(random_state = random_state)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.__clf.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.__clf.predict(X)\n",
    "\n",
    "class KNearestNeighbors(Classifier):\n",
    "    \"\"\"K-nearest neighbors classifier\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.__clf = KNeighborsClassifier()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.__clf.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.__clf.predict(X)\n",
    "\n",
    "class SVM(Classifier):\n",
    "    \"\"\"Support vector machine classifier\"\"\"\n",
    "    \n",
    "    def __init__(self, random_state: int = None):\n",
    "        self.__clf = SVC(random_state = random_state)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.__clf.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.__clf.predict(X)\n",
    "\n",
    "class Perceptron(Classifier):\n",
    "    \"\"\"Linear perceptron classifier\"\"\"\n",
    "    \n",
    "    def __init__(self, random_state: int = None):\n",
    "        self.__clf = sk_Perceptron(random_state = random_state)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.__clf.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.__clf.predict(X)\n",
    "\n",
    "class TestSet(CrossValidation):\n",
    "    \"\"\"Test set cross validation.\"\"\"\n",
    "    \n",
    "    def __init__(self, test_set_percentage: float, random_state: int = None):\n",
    "        self.__test_set_percentage = test_set_percentage\n",
    "        self.__random_state = random_state\n",
    "    \n",
    "    def split(self, X, y = None):\n",
    "        n_samples = len(X)\n",
    "        indices = np.arange(n_samples)\n",
    "        np.random.default_rng(self.__random_state).shuffle(indices)\n",
    "        stop = round(n_samples * self.__test_set_percentage)\n",
    "        test_indices = indices[:stop]\n",
    "        test_mask = np.zeros(n_samples, dtype=bool)\n",
    "        for test_index in test_indices:\n",
    "            test_mask[test_index] = True\n",
    "        train_index = indices[np.logical_not(test_mask)]\n",
    "        test_index = indices[test_mask]\n",
    "        yield train_index, test_index\n",
    "\n",
    "class LeaveOneOut(CrossValidation):\n",
    "    \"\"\"Leave-one-out cross-validation\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.__cv = sk_LeaveOneOut()\n",
    "    \n",
    "    def split(self, X, y = None):\n",
    "        return self.__cv.split(X, y)\n",
    "\n",
    "class KFold(CrossValidation):\n",
    "    \"\"\"Leave-one-out cross-validation\"\"\"\n",
    "    \n",
    "    def __init__(self, n_splits: int = 5, random_state: int = None):\n",
    "        self.__cv = sk_KFold(n_splits, shuffle = True, random_state = random_state)\n",
    "    \n",
    "    def split(self, X, y = None):\n",
    "        return self.__cv.split(X, y)\n",
    "\n",
    "class AccuracyScore(Evaluator):\n",
    "    \"\"\"Accuracy classification score.\n",
    "    \n",
    "    Computes subset accuracy: the set of labels predicted for a sample\n",
    "    must *exactly* match the corresponding set of labels in y_true.\n",
    "    \n",
    "    Score is the fraction of correctly classified samples.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def score(self, y_true, y_pred):\n",
    "        return accuracy_score(y_true, y_pred)\n",
    "\n",
    "def run(X, y, classifier: Classifier, cross_validation: CrossValidation, evaluator: Evaluator):\n",
    "    \"\"\"Classify data and return score.\"\"\"\n",
    "    score = 0\n",
    "    for train_index, test_index in cross_validation.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf = classifier.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        score = max(evaluator.score(y_test, y_pred), score)\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004394b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_dataframe = pd.read_csv(\"data/insurance.csv\")\n",
    "print('Original dataset:')\n",
    "print(insurance_dataframe)\n",
    "\n",
    "min_val = insurance_dataframe[\"charges\"].min()\n",
    "max_val = insurance_dataframe[\"charges\"].max()\n",
    "\n",
    "midpoint = (min_val + max_val) / 2\n",
    "first_quarter = (midpoint + min_val) / 2\n",
    "third_quarter = (midpoint + max_val) / 2\n",
    "\n",
    "split_1 = insurance_dataframe.loc[insurance_dataframe[\"charges\"] <= first_quarter, :].copy()\n",
    "split_2 = insurance_dataframe.loc[(first_quarter < insurance_dataframe[\"charges\"]) & (insurance_dataframe[\"charges\"] <= midpoint), :].copy()\n",
    "split_3 = insurance_dataframe.loc[(midpoint < insurance_dataframe[\"charges\"]) & (insurance_dataframe[\"charges\"] <= third_quarter), :].copy()\n",
    "split_4 = insurance_dataframe.loc[third_quarter < insurance_dataframe[\"charges\"], :].copy()\n",
    "\n",
    "split_1.loc[:, \"charges_code\"] = 0\n",
    "split_2.loc[:, \"charges_code\"] = 1\n",
    "split_3.loc[:, \"charges_code\"] = 2\n",
    "split_4.loc[:, \"charges_code\"] = 3\n",
    "\n",
    "categorized_df = pd.concat([split_1, split_2, split_3, split_4])\n",
    "\n",
    "insurance_dataframe = categorized_df[[\"age\", \"sex\", \"bmi\", \"children\", \"smoker\", \"region\", \"charges_code\"]].sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode sex\n",
    "le.fit(insurance_dataframe[\"sex\"])\n",
    "insurance_dataframe[\"sex\"] = le.transform(insurance_dataframe[\"sex\"])\n",
    "\n",
    "# Encode smoker\n",
    "le.fit(insurance_dataframe[\"smoker\"])\n",
    "insurance_dataframe[\"smoker\"] = le.transform(insurance_dataframe[\"smoker\"])\n",
    "\n",
    "# Encode region\n",
    "le.fit(insurance_dataframe[\"region\"])\n",
    "insurance_dataframe[\"region\"] = le.transform(insurance_dataframe[\"region\"])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(insurance_dataframe[[\"age\", \"sex\", \"bmi\", \"children\", \"smoker\", \"region\"]])\n",
    "insurance_dataframe[[\"age\", \"sex\", \"bmi\", \"children\", \"smoker\", \"region\"]] = scaler.transform(insurance_dataframe[[\"age\", \"sex\", \"bmi\", \"children\", \"smoker\", \"region\"]])\n",
    "\n",
    "insurance_dataframe = np.array(insurance_dataframe)\n",
    "print('Label encoded and scaled dataset:')\n",
    "print(insurance_dataframe)\n",
    "X = insurance_dataframe[:, 0:6]\n",
    "y = insurance_dataframe[:, 6]\n",
    "\n",
    "random_state: int = 42\n",
    "\n",
    "classifiers = [\n",
    "    ('Naive Bayes', NaiveBayes()),\n",
    "    ('Decision Trees', DecisionTrees(random_state = random_state)),\n",
    "    ('K-Nearest Neighbors', KNearestNeighbors()),\n",
    "    ('SVM', SVM(random_state = random_state)),\n",
    "    ('Perceptron', Perceptron(random_state = random_state)),\n",
    "]\n",
    "\n",
    "cross_validators = [\n",
    "    ('Test Set 10%', TestSet(0.1, random_state = random_state)),\n",
    "    ('Test Set 20%', TestSet(0.2, random_state = random_state)),\n",
    "    ('Test Set 30%', TestSet(0.3, random_state = random_state)),\n",
    "    ('Leave One Out', LeaveOneOut()),\n",
    "    ('5-Fold', KFold(5, random_state = random_state)),\n",
    "    ('10-Fold', KFold(10, random_state = random_state)),\n",
    "    ('15-Fold', KFold(15, random_state = random_state)),\n",
    "]\n",
    "\n",
    "accuracy_score_evaluator = AccuracyScore()\n",
    "\n",
    "for clf in classifiers:\n",
    "    for cv in cross_validators:\n",
    "        result = run(X, y, clf[1], cv[1], accuracy_score_evaluator)\n",
    "        print(f'{clf[0]}, {cv[0]}: {result}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
